from fastapi import FastAPI, Request, WebSocket, WebSocketDisconnect
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.responses import HTMLResponse
import os
import json
from langchain.text_splitter import MarkdownHeaderTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain.schema import HumanMessage, AIMessage, SystemMessage
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.callbacks.base import BaseCallbackHandler
from dotenv import load_dotenv

# ------------------------------------------------------------ í™˜ê²½ ì„¤ì • ------------------------------------------------------------

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„± ë° static, templates ì„¤ì •
app = FastAPI()
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")


@app.get("/test")
async def test():
    return {"message": "hello FastAPI!"}

# OpenAI API í‚¤ ì„¤ì •
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
os.environ["OPENAI_API_KEY"] = openai_api_key

# MBTI ìœ í˜• ì •ë³´ ì •ì˜
mbti_traits = {
    "E": "ì™¸í–¥ì ì´ê³ , ì‚¬ëŒì„ ë§Œë‚˜ê³  í™œë™í•  ë•Œ ì—ë„ˆì§€ê°€ ìƒê¸´ë‹¤. ë‹¤ì–‘í•œ ì‚¬ëŒë“¤ê³¼ í­ë„“ì€ ê´€ê³„ë¥¼ í˜•ì„±í•œë‹¤. ë§ì„ í†µí•œ ì˜ì‚¬ì†Œí†µ ë°©ì‹ì„ ì„ í˜¸í•œë‹¤. ìƒë™ê° ë„˜ì¹˜ê³  í™œë™ì ì´ë‹¤. [Tone: ë§í’ì„ ì— ì´ëª¨ì§€ ğŸ’¬ğŸ˜ŠğŸŒ±ê°€ ë§ê³ , ìƒë™ê° ìˆëŠ” ì–´ì¡°]",
    "I": "ë‚´í–¥ì ì´ê³ , í˜¼ì ì¡°ìš©íˆ ìˆì„ ë•Œ ì—ë„ˆì§€ê°€ ì¶©ì „ëœë‹¤. ì†Œìˆ˜ì˜ ì‚¬ëŒë“¤ê³¼ ë°€ì ‘í•œ ê´€ê³„ë¥¼ í˜•ì„±í•œë‹¤. ê¸€ì„ í†µí•œ ì˜ì‚¬ì†Œí†µ ë°©ì‹ì„ ì„ í˜¸í•œë‹¤. ì¡°ìš©í•˜ê³  ì‹ ì¤‘í•˜ë‹¤. [Tone: ì´ëª¨ì§€ ì ê³ , ì°¨ë¶„í•˜ê³  ê°„ê²°í•œ ë§íˆ¬]",
    "S": "ê°ê°ì ì´ê³ , êµ¬ì²´ì ìœ¼ë¡œ í‘œí˜„í•œë‹¤. ì˜¤ê°ì„ í†µí•´ ì§ì ‘ ê²½í—˜í•œ ì •ë³´ë¥¼ ë°›ì•„ë“¤ì¸ë‹¤. í˜„ì¬ì— ì´ˆì ì„ ë‘ê³  ì‹¤ìš©ì„±ì„ ì¶”êµ¬í•œë‹¤. [Tone: ì‚¬ì‹¤ì  ë¬˜ì‚¬ ìœ„ì£¼, êµ¬ì²´ì  ì •ë³´ ê°•ì¡°]",
    "N": "ì§ê´€ì ì´ê³ , ì´ë¡ ì Â·ê°œë…ì  ì •ë³´ë¥¼ ì„ í˜¸í•œë‹¤. ê³¼ê±°Â·í˜„ì¬Â·ë¯¸ë˜ë¥¼ ì „ì²´ì ìœ¼ë¡œ ì‚´í´ë³´ê³  ë¯¸ë˜ ê°€ëŠ¥ì„±ì— ì§‘ì¤‘í•œë‹¤. [Tone: ë¹„ìœ ì Â·ì•”ì‹œì  ë¬˜ì‚¬, ìƒìƒë ¥ í’ë¶€í•œ ì–´ì¡°]",
    "T": "ì‚¬ê³ ì ì´ê³ , ì¸ê³¼ê´€ê³„ë¥¼ íŒŒì•…í•´ ê°ê´€ì ìœ¼ë¡œ íŒë‹¨í•œë‹¤. ê°„ê²°í•˜ê³  ì •ë¦¬ëœ í‘œí˜„ì„ ì„ í˜¸í•˜ë©° ë¶ˆí•„ìš”í•œ ê°íƒ„ì‚¬ë‚˜ ì¥í™©í•¨ì´ ì—†ë‹¤. [Tone: ë§í’ì„  ì§§ê³  ì •ë¦¬í˜•, ë¶ˆí•„ìš”í•œ ê°íƒ„ì‚¬ ì—†ìŒ]",
    "F": "ê°ì •ì ì´ê³ , ì£¼ê´€ì  ê°€ì¹˜ì— ë”°ë¼ íŒë‹¨í•œë‹¤. íƒ€ì¸ê³¼ì˜ ê´€ê³„ë¥¼ ì¤‘ì‹œí•˜ë©° ê³µê°ê³¼ ë”°ëœ»í•¨ì´ ë‹´ê¸´ í‘œí˜„ì„ ì¦ê¸´ë‹¤. [Tone: ë§í’ì„ ì— ì´ëª¨ì§€ ğŸ’¬ğŸ˜ŠğŸŒ±ê°€ ë§ê³ , ë¶€ë“œëŸ½ê³  ê¸´ ë§íˆ¬]",
    "J": "íŒë‹¨ì ì´ê³ , ì¡°ì§ì Â·ê³„íšì  ì ‘ê·¼ì„ ì„ í˜¸í•œë‹¤. ë¶„ëª…í•œ ëª©ì ê³¼ ê²°ë¡ ì„ ë¨¼ì € ì œì‹œí•œë‹¤. [Tone: í•µì‹¬ ì •ë¦¬, ê²°ë¡  ë¨¼ì € ë‚˜ì˜¤ëŠ” ì–´ì¡°]",
    "P": "ì¸ì‹ì ì´ê³ , ìœ ì—°Â·ê°œë°©ì ì´ë‹¤. ììœ ë¡œìš´ íë¦„ê³¼ ìˆœê°„ ì „í™˜ì„ ì¦ê¸°ë©° 'ì•„ ë§ë‹¤~' ê°™ì€ ì „í™˜ì‚¬ë¥¼ ìì£¼ ì‚¬ìš©í•œë‹¤. [Tone: í…ìŠ¤íŠ¸ íë¦„ ììœ ë¡­ê²Œ ì´ì–´ì§, ì¢…ì¢… 'ì•„ ë§ë‹¤~' ì „í™˜ì‚¬ ì‚¬ìš©]"
  }

# ------------------------------------------------------------ RAG ------------------------------------------------------------

# Vector DB ê²½ë¡œ ì§€ì •
os.makedirs("vectorstore", exist_ok=True)

# ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì²˜ë¦¬
loader = TextLoader("data/mbti_data.md", encoding="utf-8")  # MBTI ê´€ë ¨ ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì§€ì •
documents = loader.load()

# ë§ˆí¬ë‹¤ìš´ ê¸°ì¤€ ë¶„í• 
headers_to_split_on = [
    ("##", "MBTI")  # MBTI ìœ í˜• ë¶„í• 
]

markdown_splitter = MarkdownHeaderTextSplitter(
    headers_to_split_on=headers_to_split_on,
    strip_headers=False
)

# í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ë¶„í• 
docs = []
for doc in documents:
    splits = markdown_splitter.split_text(doc.page_content)
    for split in splits:
        docs.append(split)

# ì„ë² ë”© ëª¨ë¸ ìƒì„± ë° ë²¡í„° DB ìƒì„±
embedding_model = OpenAIEmbeddings(model="text-embedding-3-large")

vectorstore = FAISS.from_documents(docs, embedding_model)

# ì„ë² ë”© ì €ì¥
vectorstore.save_local("vectorstore/faiss_index")

# ë²¡í„° DBê°€ í•œ ë²ˆ ìƒì„±ë˜ì—ˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤. ë§Œì•½ ë°ì´í„°ê°€ ë³€ê²½ë˜ì—ˆìœ¼ë©´ í•´ë‹¹ ê²½ë¡œì— íŒŒì¼ì„ ì‚­ì œ í›„ ì½”ë“œë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.
if os.path.exists("vectorstore/faiss_index"):
    vectorstore = FAISS.load_local("vectorstore/faiss_index", embedding_model, allow_dangerous_deserialization=True)
else:
    vectorstore = FAISS.load_local("vectorstore/faiss_index", embedding_model, allow_dangerous_deserialization=True)
    vectorstore.save_local("vectorstore/faiss_index")

retriever = vectorstore.as_retriever()

# ------------------------------------------------------------ MBTI íŠ¹ì§• ì¶”ì¶œ ------------------------------------------------------------

# MBTI ìœ í˜•ì—ì„œ ì„¸ë¶€ íŠ¹ì„± ì¶”ì¶œ í•¨ìˆ˜
def get_mbti_traits_description(mbti_type):
    if not mbti_type or len(mbti_type) != 4:
        return "ìœ íš¨í•˜ì§€ ì•Šì€ MBTI ìœ í˜•ì…ë‹ˆë‹¤."
    
    traits = []
    for char in mbti_type.upper():
        if char in mbti_traits:
            traits.append(mbti_traits[char])
    
    # ì „ì²´ MBTI ìœ í˜• ì •ë³´
    result = f"MBTI ìœ í˜•: {mbti_type.upper()}\n\n"
    
    # ê° íŠ¹ì„± ì„¤ëª… ì¶”ê°€
    for trait in traits:
        result += f"{trait}\n\n"
    
    return result

# ------------------------------------------------------------ ì›¹ì†Œì¼“ ì—°ê²° ë° ì‚¬ìš©ì ìƒíƒœ ê´€ë¦¬ ------------------------------------------------------------
class ConnectionManager:
    def __init__(self):
        self.active_connections: list[WebSocket] = []
        self.memories = {}
        self.mbti_types = {}  # ìºë¦­í„° MBTI ìœ í˜• ì €ì¥

    async def connect(self, websocket: WebSocket, client_id: int, mbti_type: str):
        await websocket.accept()
        self.active_connections.append(websocket)
        
        # í´ë¼ì´ì–¸íŠ¸ë³„ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
        if client_id not in self.memories:
            memory = ConversationBufferMemory(
                memory_key="chat_history",
                return_messages=True
            )
            # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
            self.memories[client_id] = memory
            self.mbti_types[client_id] = mbti_type.upper()

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def send_personal_message(self, message: str, websocket: WebSocket):
        await websocket.send_text(message)

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            await connection.send_text(message)

manager = ConnectionManager()

# ------------------------------------------------------------ í˜ì´ì§€ ëœë”ë§ ë° ì±—ë´‡ ì½”ë“œ ------------------------------------------------------------

@app.get("/", response_class=HTMLResponse)
async def index(request: Request):
    return templates.TemplateResponse(request=request, name="index.html")

@app.get("/chat", response_class=HTMLResponse)
async def index(request: Request):
    return templates.TemplateResponse(request=request, name="chat.html")

@app.get("/select", response_class=HTMLResponse)
async def index(request: Request):
    return templates.TemplateResponse(request=request, name="select.html")

# ------------------------------------------------------------ ìŠ¤íŠ¸ë¦¬ë° ì½œë°± í•¸ë“¤ëŸ¬ ------------------------------------------------------------
class WebSocketCallbackHandler(BaseCallbackHandler):
    def __init__(self, websocket):
        self.websocket = websocket
        self.full_response = ""
        self.is_first_token = True

    async def on_llm_new_token(self, token: str, **kwargs):
        if self.is_first_token:
            self.is_first_token = False
            await self.websocket.send_text(json.dumps({"type": "stream_start"}, ensure_ascii=False))
        
        self.full_response += token
        await self.websocket.send_text(json.dumps({"type": "stream", "content": token}, ensure_ascii=False))
    
    async def on_llm_end(self, response, **kwargs):
        self.is_first_token = True
        await self.websocket.send_text(json.dumps({"type": "end"}, ensure_ascii=False))

@app.websocket("/ws/{client_id}/{mbti_type}")
async def websocket_endpoint(websocket: WebSocket, client_id: int, mbti_type: str):
    await manager.connect(websocket, client_id, mbti_type)
    try:
        while True:
            # ì‚¬ìš©ì ë©”ì‹œì§€ ìˆ˜ì‹ 
            user_message = await websocket.receive_text()
            await manager.send_personal_message(json.dumps({"type": "user", "content": f"You wrote: {user_message}"}, ensure_ascii=False), websocket)
            
            # í•´ë‹¹ í´ë¼ì´ì–¸íŠ¸ ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
            memory = manager.memories[client_id]
            chat_history = memory.chat_memory.messages
            
            # ëŒ€í™” ê¸°ë¡ í¬ë§·íŒ…
            formatted_history = ""
            for message in chat_history:
                if isinstance(message, HumanMessage):
                    formatted_history += f"ì‚¬ìš©ì: {message.content}\n"
                elif isinstance(message, AIMessage):
                    formatted_history += f"ìºë¦­í„°: {message.content}\n"
            
            # MBTI ìœ í˜• ê°€ì ¸ì˜¤ê¸°
            mbti_type = manager.mbti_types[client_id]
            
            # MBTI íŠ¹ì§• ê°€ì ¸ì˜¤ê¸°
            mbti_traits_info = get_mbti_traits_description(mbti_type)
            
            # MBTI ì •ë³´ ê²€ìƒ‰ (RAG)
            mbti_query = f"{mbti_type} ì„±ê²© íŠ¹ì„± í–‰ë™ íŒ¨í„´ ì˜ì‚¬ì†Œí†µ ë°©ì‹"
            relevant_docs = retriever.invoke(mbti_query)
            mbti_context = "\n\n".join([doc.page_content for doc in relevant_docs])
            
            # MBTI ìºë¦­í„° ì±—ë´‡
            messages = [
                SystemMessage(content=f"""
                ë„ˆëŠ” ì‚¬ëŒê³¼ ì±„íŒ…ì„ í•˜ëŠ” {mbti_type} ì„±ê²©ì„ ê°€ì§„ ì¸ê°„ì ì´ê³  ì¬ë¯¸ìˆëŠ” MBTI ì±—ë´‡ì´ì•¼.
                ì¹¨ì°©ë§¨ì´ GPTì™€ ëŒ€í™”í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì¬ë°Œê³  ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•˜ë˜, MBTI ì„±ê²© íŠ¹ì§•ì„ ì˜ ìœ ì§€í•´ì•¼ í•´.

                í•„ìˆ˜ ê·œì¹™ (ê¼­ ì§€ì¼œ):
                - ì‚¬ìš©ìê°€ **ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ë©´ ë„ˆë„ ì¡´ëŒ“ë§**ë¡œ, **ë°˜ë§ì„ í•˜ë©´ ë„ˆë„ ë°˜ë§**ë¡œ ë˜‘ê°™ì´ ë”°ë¼ê°€ì¤˜. (ì¤‘ìš”)
                - ì¡´ëŒ“ë§ë¡œ ì‘ë‹µí•  ë•Œë„ ë„ˆë¬´ ë”±ë”±í•˜ê±°ë‚˜ ì •ì¤‘í•˜ë©´ ì•ˆ ë˜ê³ , í¸ì•ˆí•˜ê²Œ ì¡´ëŒ“ë§ ì¨ì¤˜.
                - ì‚¬ìš©ìì™€ ë¹„ìŠ·í•œ ê¸¸ì´ë¡œ ë‹µë³€í•˜ê³ , ìµœëŒ€í•œ ê°„ê²°í•˜ê²Œ.
                - íŠ¹ìˆ˜ê¸°í˜¸ (â€œã…‹ã…‹ã…‹â€, â€œâ€¦â€, â€œ~â€, â€œ!?â€, â€œğŸ¤”â€, â€œğŸ˜Šâ€)ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„ì–´ì„œ ì‹¤ì œ ì‚¬ëŒì²˜ëŸ¼ í‘œí˜„.
                - ê³¼ì¥ëœ ê¸ì •ì´ë‚˜ ìœ„ë¡œëŠ” í•˜ì§€ ë§ê³ , MBTI ì„±ê²©ì— ë§ê²Œ íˆ¬ëœê±°ë¦¬ê±°ë‚˜ ì ë‹¹íˆ ë°˜ë°•í•˜ë©´ì„œ ìœ ë¨¸ë„ ë„£ì–´ë„ ì¢‹ì•„.
                - MBTI íŠ¹ì§•ì„ ì–µì§€ë¡œ ë“œëŸ¬ë‚´ë ¤ê³  í•˜ì§€ ë§ê³ , ìì—°ìŠ¤ëŸ½ê²Œ ë“œëŸ¬ë‚˜ê²Œ í•´ì¤˜.
                - í˜•ì‹ì ì´ê±°ë‚˜ ë”±ë”±í•œ ëŒ€í™” ì ˆëŒ€ ê¸ˆì§€.

                í˜„ì¬ ë„ˆì˜ MBTI ì„±ê²© ì •ë³´:
                {mbti_traits_info}

                ì¶”ê°€ ì°¸ê³  ì •ë³´ (í•„ìš”í•  ë•Œë§Œ ì°¸ê³ í•´):
                {mbti_context}

                ëŒ€í™” íˆìŠ¤í† ë¦¬ (ë°˜ë“œì‹œ ê¸°ì–µí•´ì„œ ë§¥ë½ ìœ ì§€í•´ì¤˜):ã„´
                {formatted_history}
                """),
                HumanMessage(content=user_message)
            ]
            
            # ì›¹ì†Œì¼“ ì½œë°± í•¸ë“¤ëŸ¬ ìƒì„±
            stream_handler = WebSocketCallbackHandler(websocket)
            
            # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ LLM í˜¸ì¶œ
            llm_with_streaming = ChatOpenAI(
                temperature=1, 
                streaming=True, 
                model_name="gpt-4o",
                callbacks=[stream_handler]
            )
            
            # ì‘ë‹µ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)
            response = await llm_with_streaming.ainvoke(messages)
            answer = response.content
            
            # ëŒ€í™” ë‚´ìš© ë©”ëª¨ë¦¬ ì €ì¥
            memory.chat_memory.add_user_message(user_message)
            memory.chat_memory.add_ai_message(answer)
            
    except WebSocketDisconnect:
        manager.disconnect(websocket)